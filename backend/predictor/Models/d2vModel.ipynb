{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting Cython==0.29.32\n",
      "  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "     ------------------------------------- 986.3/986.3 kB 30.5 MB/s eta 0:00:00\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: scipy>=1.7.0 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.5 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\progams\\anaconda\\envs\\textsimilarityapi\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.0.4)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20431 sha256=347f0ce0acc4b9c80267ca63137cff1c6fb1ad7beacf2f1f7bbca5d629f9aa97\n",
      "  Stored in directory: c:\\users\\yago\\appdata\\local\\pip\\cache\\wheels\\01\\02\\ee\\df0699282986903a384b69aab4413af9efd26b3612b5dccc9e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3514 sha256=dbfdd0fe40388b1ebb649d8821e7d14edaf9e21658422b3f7bc1da7adc4c70bb\n",
      "  Stored in directory: c:\\users\\yago\\appdata\\local\\pip\\cache\\wheels\\43\\aa\\48\\5c66b931ff013ad19774081aa19656637af5c0cc33b5494b30\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: smart-open, Cython, simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "Successfully installed Cython-0.29.32 FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.9.0 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "\n",
    "    dataset_text_a = dataset.iloc[:, 1]\n",
    "    dataset_text_b = dataset.iloc[:, 2]\n",
    "\n",
    "    return [dataset_text_a, dataset_text_b]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def process_data(corpus):\n",
    "    # Create a Set of frequent words\n",
    "    stoplist = set('a e o ou Ã '.split(' '))\n",
    "\n",
    "    # Lowercase each document, split it by white spaces and filter out stoplist words\n",
    "    data = [\n",
    "        [word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in corpus\n",
    "    ]\n",
    "\n",
    "    # Count words frequencies\n",
    "    frequency = defaultdict(int)\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yago\\AppData\\Local\\Temp\\ipykernel_13284\\3805075144.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  texts = np.asarray(pp)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Iterator operand or requested dtype holds references, but the REFS_OK flag was not enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m frequency \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(frequency)\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnditer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m      9\u001B[0m     frequency[x] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(frequency)\n",
      "\u001B[1;31mTypeError\u001B[0m: Iterator operand or requested dtype holds references, but the REFS_OK flag was not enabled"
     ]
    }
   ],
   "source": [
    "data = read_data('./Data/train.csv')\n",
    "pp = process_data(data[0])\n",
    "\n",
    "texts = np.asarray(pp)\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "print(frequency)\n",
    "for x in np.nditer(texts):\n",
    "    frequency[x] += 1\n",
    "\n",
    "print(frequency)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
